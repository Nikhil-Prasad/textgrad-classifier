# .github/workflows/ci.yml
name: TextGrad Prompt Optimization CI

on:
  push:
    branches: [ main ]
  pull_request:
    branches: [ main ]
  workflow_dispatch:  # Allow manual trigger

jobs:
  test-prompt-optimization:
    runs-on: ubuntu-latest
    env:
      OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
      # OPENAI_ORG_ID: ${{ secrets.OPENAI_ORG_ID }}  # Optional

    steps:
      # Check out repository code
      - name: Checkout repository
        uses: actions/checkout@v4

      # Set up Python
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'

      # 3️⃣  Install Poetry CLI (global)
      - name: Install Poetry
        run: pipx install poetry

      # 4️⃣  Cache Poetry virtual-env to speed up future runs (optional but nice)
      - name: Cache Poetry venv
        uses: actions/cache@v4
        with:
          key: poetry-venv-${{ runner.os }}-${{ hashFiles('**/poetry.lock') }}
          path: ~/.cache/pypoetry

      # 5️⃣  Install project dependencies into Poetry’s virtual-env
      - name: Install dependencies
        run: poetry install --no-interaction --no-ansi

      # 6️⃣  Generate datasets
      - name: Create demo CSVs
        run: |
          poetry run python scripts/prepare_data.py contact --rows 40
          poetry run python scripts/prepare_data.py issues --limit 100

      # 7️⃣  Run TextGrad on contact config
      - name: Run TextGrad Contact Notes Classification
        run: |
          poetry run python scripts/run_textgrad.py configs/contact.yaml
        continue-on-error: false  # Fail the job if accuracy < 0.70

      # 8️⃣  Verify accuracy threshold (backup check)
      - name: Verify accuracy threshold
        run: |
          # Check if the run succeeded (exit code 0 means success)
          if [ $? -ne 0 ]; then
            echo "TextGrad training failed to meet accuracy threshold"
            exit 1
          fi
          
          # Optional: Parse and display metrics from the latest output
          LATEST_OUTPUT=$(ls -t outputs/*/metrics_summary.json | head -1)
          if [ -f "$LATEST_OUTPUT" ]; then
            echo "Metrics summary:"
            cat "$LATEST_OUTPUT"
          fi

      # 9️⃣  Run TextGrad on issues config (optional)
      - name: Run TextGrad Issues Classification
        run: |
          poetry run python scripts/run_textgrad.py configs/issues.yaml
        continue-on-error: true  # Don't fail CI if issues dataset fails

      # 10️⃣  Run tests (if any)
      - name: Run tests
        run: poetry run pytest || echo "No tests found"
        continue-on-error: true

      # 11️⃣  Archive results
      - name: Upload TextGrad outputs
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: textgrad-outputs
          path: outputs/
          retention-days: 30
