# Configuration for TextGrad on the issue-report classification task (binary: bug vs non-bug)
experiment: "GitHub Issue Bug Detection"
model:
  engine: "gpt-4o"  # Using OpenAI GPT-4o directly
  max_tokens: 256
  temperature: 0.2
prompt:
  # Initial prompt templates for system and user roles
  system: |
    You are a software engineering assistant that identifies bug reports in GitHub issues.
    Based on the title and description, determine if the issue is reporting a bug or not.
    Be concise and answer with only the classification label.
  user: |
    Here is a GitHub issue report:
    Title: "{title}"
    Description: "{body}"
    
    Is this issue reporting a bug? Answer with exactly one of: "bug" or "non_bug".
training:
  epochs: 3             # Number of TextGrad optimization iterations
  batch_size: 5         # Number of samples to evaluate per batch
  learning_rate: 1.0    # TextGrad "learning rate" for prompt adjustments
  max_prompt_chars: 3000   # Maximum prompt size in characters (~750 tokens)
  max_train_samples: 50   # Limit training samples for faster iteration (optional)
  gradient_memory: 5    # Keep only last N gradients to prevent context overflow
evaluation:
  # Define evaluation metric and settings
  expected_classes: ["bug", "non_bug"]
  metric: "accuracy"
  success_threshold: 0.80   # Desired accuracy for CI pass/fail (higher for binary task)
data:
  csv_path: "data/issues_binary.csv"
  text_columns: ["title", "body"]  # Multiple columns for input
  label_column: "label"
  train_test_split: 0.8